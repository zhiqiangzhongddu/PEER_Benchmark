{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-02T16:54:59.620250Z",
     "start_time": "2023-07-02T16:54:58.126377Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from torchdrug.utils import comm, pretty\n",
    "from torchdrug import data, core, utils\n",
    "from torch.utils import data as torch_data\n",
    "\n",
    "from IPython import get_ipython\n",
    "def is_notebook() -> bool:\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        if shell == 'ZMQInteractiveShell':\n",
    "            return True   # Jupyter notebook or qtconsole\n",
    "        elif shell == 'TerminalInteractiveShell':\n",
    "            return False  # Terminal running IPython\n",
    "        else:\n",
    "            return False  # Other type (?)\n",
    "    except NameError:\n",
    "        return False      # Probably standard Python interpreter\n",
    "\n",
    "if is_notebook():\n",
    "    sys.path.append('/home/zhiqiang/PEER_Benchmark')\n",
    "else:\n",
    "    sys.path.append(os.path.dirname(os.path.dirname(__file__)))\n",
    "\n",
    "from peer import protbert, util, flip\n",
    "from script.run_single import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T16:54:59.626086Z",
     "start_time": "2023-07-02T16:54:59.623865Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# train the model, same as PEER code\n",
    "args = parse_args()\n",
    "\n",
    "args.config = '/home/zhiqiang/PEER_Benchmark/config/single_task/ESM/gb1_ESM_fix.yaml' \\\n",
    "    if is_notebook() else os.path.realpath(args.config)\n",
    "cfg = util.load_config(args.config)\n",
    "if cfg.dataset[\"class\"] != \"Fluorescence\":\n",
    "    cfg.dataset[\"split\"] = args.split"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T16:54:59.626228Z",
     "start_time": "2023-07-02T16:54:59.624140Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:54:59   Config file: /home/zhiqiang/PEER_Benchmark/config/single_task/ESM/gb1_ESM_fix.yaml\n",
      "16:54:59   {'dataset': {'atom_feature': None,\n",
      "             'bond_feature': None,\n",
      "             'class': 'GB1',\n",
      "             'path': '~/scratch/protein-datasets/',\n",
      "             'split': 'two_vs_rest',\n",
      "             'transform': {'class': 'Compose',\n",
      "                           'transforms': [{'class': 'ProteinView',\n",
      "                                           'view': 'residue'}]}},\n",
      " 'engine': {'batch_size': 32, 'gpus': [0]},\n",
      " 'eval_metric': 'spearmanr',\n",
      " 'fix_encoder': True,\n",
      " 'optimizer': {'class': 'Adam', 'lr': 5e-05},\n",
      " 'output_dir': '~/scratch/torchprotein_output/',\n",
      " 'task': {'class': 'PropertyPrediction',\n",
      "          'criterion': 'mse',\n",
      "          'metric': ['mae', 'rmse', 'spearmanr'],\n",
      "          'model': {'class': 'ESM',\n",
      "                    'model': 'ESM-1b',\n",
      "                    'path': '~/scratch/protein-model-weights/esm-model-weights/',\n",
      "                    'readout': 'mean'},\n",
      "          'normalization': False,\n",
      "          'num_mlp_layer': 2},\n",
      " 'train': {'num_epoch': 30}}\n",
      "16:54:59   Output dir: /home/zhiqiang/scratch/torchprotein_output/PropertyPrediction/GB1/ESM_2023-07-02-16-54-59\n"
     ]
    }
   ],
   "source": [
    "set_seed(args.seed)\n",
    "output_dir = util.create_working_directory(cfg)\n",
    "logger = util.get_root_logger()\n",
    "if comm.get_rank() == 0:\n",
    "    logger.warning(\"Config file: %s\" % args.config)\n",
    "    logger.warning(pprint.pformat(cfg))\n",
    "    logger.warning(\"Output dir: %s\" % output_dir)\n",
    "    shutil.copyfile(args.config, os.path.basename(args.config))\n",
    "os.chdir(output_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T16:54:59.656864Z",
     "start_time": "2023-07-02T16:54:59.644495Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T16:54:59.656993Z",
     "start_time": "2023-07-02T16:54:59.650745Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:54:59   Extracting /home/zhiqiang/scratch/protein-datasets/gb1/splits.zip to /home/zhiqiang/scratch/protein-datasets/gb1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading /home/zhiqiang/scratch/protein-datasets/gb1/splits/two_vs_rest.csv: 100%|██████████| 8734/8734 [00:00<00:00, 156473.26it/s]\n",
      "Constructing proteins from sequences: 100%|██████████| 8733/8733 [00:06<00:00, 1317.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:55:06   GB1(\n",
      "  #sample: 8733\n",
      "  #task: 1\n",
      ")\n",
      "16:55:06   #train: 381, #valid: 43, #test: 8309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:55:23   Preprocess training set\n",
      "16:55:25   {'batch_size': 32,\n",
      " 'class': 'core.Engine',\n",
      " 'gpus': [0],\n",
      " 'gradient_interval': 1,\n",
      " 'log_interval': 100,\n",
      " 'logger': 'logging',\n",
      " 'num_worker': 0,\n",
      " 'optimizer': {'amsgrad': False,\n",
      "               'betas': (0.9, 0.999),\n",
      "               'capturable': False,\n",
      "               'class': 'optim.Adam',\n",
      "               'eps': 1e-08,\n",
      "               'foreach': None,\n",
      "               'lr': 5e-05,\n",
      "               'maximize': False,\n",
      "               'weight_decay': 0},\n",
      " 'scheduler': None,\n",
      " 'task': {'class': 'tasks.PropertyPrediction',\n",
      "          'criterion': 'mse',\n",
      "          'graph_construction_model': None,\n",
      "          'metric': ['mae', 'rmse', 'spearmanr'],\n",
      "          'mlp_batch_norm': False,\n",
      "          'mlp_dropout': 0,\n",
      "          'model': {'class': 'models.ESM',\n",
      "                    'model': 'ESM-1b',\n",
      "                    'path': '~/scratch/protein-model-weights/esm-model-weights/',\n",
      "                    'readout': 'mean'},\n",
      "          'normalization': False,\n",
      "          'num_class': None,\n",
      "          'num_mlp_layer': 2,\n",
      "          'task': ['target'],\n",
      "          'verbose': 0},\n",
      " 'test_set': {'class': 'dataset.Subset',\n",
      "              'dataset': {'atom_feature': None,\n",
      "                          'bond_feature': None,\n",
      "                          'class': 'datasets.GB1',\n",
      "                          'path': '~/scratch/protein-datasets/',\n",
      "                          'split': 'two_vs_rest',\n",
      "                          'transform': {'class': 'transforms.Compose',\n",
      "                                        'transforms': [{'class': 'transforms.ProteinView',\n",
      "                                                        'keys': 'graph',\n",
      "                                                        'view': 'residue'}]},\n",
      "                          'verbose': 1},\n",
      "              'indices': range(424, 8733)},\n",
      " 'train_set': {'class': 'dataset.Subset',\n",
      "               'dataset': {'atom_feature': None,\n",
      "                           'bond_feature': None,\n",
      "                           'class': 'datasets.GB1',\n",
      "                           'path': '~/scratch/protein-datasets/',\n",
      "                           'split': 'two_vs_rest',\n",
      "                           'transform': {'class': 'transforms.Compose',\n",
      "                                         'transforms': [{'class': 'transforms.ProteinView',\n",
      "                                                         'keys': 'graph',\n",
      "                                                         'view': 'residue'}]},\n",
      "                           'verbose': 1},\n",
      "               'indices': range(0, 381)},\n",
      " 'valid_set': {'class': 'dataset.Subset',\n",
      "               'dataset': {'atom_feature': None,\n",
      "                           'bond_feature': None,\n",
      "                           'class': 'datasets.GB1',\n",
      "                           'path': '~/scratch/protein-datasets/',\n",
      "                           'split': 'two_vs_rest',\n",
      "                           'transform': {'class': 'transforms.Compose',\n",
      "                                         'transforms': [{'class': 'transforms.ProteinView',\n",
      "                                                         'keys': 'graph',\n",
      "                                                         'view': 'residue'}]},\n",
      "                           'verbose': 1},\n",
      "               'indices': range(381, 424)}}\n",
      "16:55:25   Extracting /home/zhiqiang/scratch/protein-datasets/gb1/splits.zip to /home/zhiqiang/scratch/protein-datasets/gb1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading /home/zhiqiang/scratch/protein-datasets/gb1/splits/two_vs_rest.csv: 100%|██████████| 8734/8734 [00:00<00:00, 183694.30it/s]\n",
      "Constructing proteins from sequences: 100%|██████████| 8733/8733 [00:06<00:00, 1316.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:55:31   GB1(\n",
      "  #sample: 8733\n",
      "  #task: 1\n",
      ")\n",
      "16:55:31   #train: 381, #valid: 43, #test: 8309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "solver = build_solver(cfg, logger)\n",
    "# build dataset\n",
    "_dataset = core.Configurable.load_config_dict(cfg.dataset)\n",
    "if \"test_split\" in cfg:\n",
    "    train_set, valid_set, test_set = _dataset.split(['train', 'valid', cfg.test_split])\n",
    "else:\n",
    "    train_set, valid_set, test_set = _dataset.split()\n",
    "if comm.get_rank() == 0:\n",
    "    logger.warning(_dataset)\n",
    "    logger.warning(\"#train: %d, #valid: %d, #test: %d\" % (len(train_set), len(valid_set), len(test_set)))\n",
    "\n",
    "# build task model\n",
    "if cfg.task[\"class\"] in [\"PropertyPrediction\", \"InteractionPrediction\"]:\n",
    "    cfg.task.task = _dataset.tasks\n",
    "task = core.Configurable.load_config_dict(cfg.task)\n",
    "\n",
    "# fix the pre-trained encoder if specified\n",
    "fix_encoder = cfg.get(\"fix_encoder\", False)\n",
    "fix_encoder2 = cfg.get(\"fix_encoder2\", False)\n",
    "if fix_encoder:\n",
    "    for p in task.model.parameters():\n",
    "        p.requires_grad = False\n",
    "if fix_encoder2:\n",
    "    for p in task.model2.parameters():\n",
    "        p.requires_grad = False"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T16:55:48.655112Z",
     "start_time": "2023-07-02T16:54:59.650826Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T16:55:48.655643Z",
     "start_time": "2023-07-02T16:55:48.654442Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:55:48   Preprocess training set\n",
      "16:55:49   {'batch_size': 32,\n",
      " 'class': 'core.Engine',\n",
      " 'gpus': [0],\n",
      " 'gradient_interval': 1,\n",
      " 'log_interval': 100,\n",
      " 'logger': 'logging',\n",
      " 'num_worker': 0,\n",
      " 'optimizer': {'amsgrad': False,\n",
      "               'betas': (0.9, 0.999),\n",
      "               'capturable': False,\n",
      "               'class': 'optim.Adam',\n",
      "               'eps': 1e-08,\n",
      "               'foreach': None,\n",
      "               'lr': 5e-05,\n",
      "               'maximize': False,\n",
      "               'weight_decay': 0},\n",
      " 'scheduler': None,\n",
      " 'task': {'class': 'tasks.PropertyPrediction',\n",
      "          'criterion': 'mse',\n",
      "          'graph_construction_model': None,\n",
      "          'metric': ['mae', 'rmse', 'spearmanr'],\n",
      "          'mlp_batch_norm': False,\n",
      "          'mlp_dropout': 0,\n",
      "          'model': {'class': 'models.ESM',\n",
      "                    'model': 'ESM-1b',\n",
      "                    'path': '~/scratch/protein-model-weights/esm-model-weights/',\n",
      "                    'readout': 'mean'},\n",
      "          'normalization': False,\n",
      "          'num_class': None,\n",
      "          'num_mlp_layer': 2,\n",
      "          'task': ['target'],\n",
      "          'verbose': 0},\n",
      " 'test_set': {'class': 'dataset.Subset',\n",
      "              'dataset': {'atom_feature': None,\n",
      "                          'bond_feature': None,\n",
      "                          'class': 'datasets.GB1',\n",
      "                          'path': '~/scratch/protein-datasets/',\n",
      "                          'split': 'two_vs_rest',\n",
      "                          'transform': {'class': 'transforms.Compose',\n",
      "                                        'transforms': [{'class': 'transforms.ProteinView',\n",
      "                                                        'keys': 'graph',\n",
      "                                                        'view': 'residue'}]},\n",
      "                          'verbose': 1},\n",
      "              'indices': range(424, 8733)},\n",
      " 'train_set': {'class': 'dataset.Subset',\n",
      "               'dataset': {'atom_feature': None,\n",
      "                           'bond_feature': None,\n",
      "                           'class': 'datasets.GB1',\n",
      "                           'path': '~/scratch/protein-datasets/',\n",
      "                           'split': 'two_vs_rest',\n",
      "                           'transform': {'class': 'transforms.Compose',\n",
      "                                         'transforms': [{'class': 'transforms.ProteinView',\n",
      "                                                         'keys': 'graph',\n",
      "                                                         'view': 'residue'}]},\n",
      "                           'verbose': 1},\n",
      "               'indices': range(0, 381)},\n",
      " 'valid_set': {'class': 'dataset.Subset',\n",
      "               'dataset': {'atom_feature': None,\n",
      "                           'bond_feature': None,\n",
      "                           'class': 'datasets.GB1',\n",
      "                           'path': '~/scratch/protein-datasets/',\n",
      "                           'split': 'two_vs_rest',\n",
      "                           'transform': {'class': 'transforms.Compose',\n",
      "                                         'transforms': [{'class': 'transforms.ProteinView',\n",
      "                                                         'keys': 'graph',\n",
      "                                                         'view': 'residue'}]},\n",
      "                           'verbose': 1},\n",
      "               'indices': range(381, 424)}}\n"
     ]
    }
   ],
   "source": [
    "# build solver\n",
    "cfg.optimizer.params = task.parameters()\n",
    "optimizer = core.Configurable.load_config_dict(cfg.optimizer)\n",
    "if not \"scheduler\" in cfg:\n",
    "    scheduler = None\n",
    "else:\n",
    "    cfg.scheduler.optimizer = optimizer\n",
    "    scheduler = core.Configurable.load_config_dict(cfg.scheduler)\n",
    "\n",
    "solver = core.Engine(task, train_set, valid_set, test_set, optimizer, scheduler, **cfg.engine)\n",
    "if \"lr_ratio\" in cfg:\n",
    "    cfg.optimizer.params = [\n",
    "        {'params': solver.model.model.parameters(), 'lr': cfg.optimizer.lr * cfg.lr_ratio},\n",
    "        {'params': solver.model.mlp.parameters(), 'lr': cfg.optimizer.lr}\n",
    "    ]\n",
    "    optimizer = core.Configurable.load_config_dict(cfg.optimizer)\n",
    "    solver.optimizer = optimizer\n",
    "if \"checkpoint\" in cfg:\n",
    "    solver.load(cfg.checkpoint, load_optimizer=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T16:55:49.336645Z",
     "start_time": "2023-07-02T16:55:48.659796Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T16:55:49.352970Z",
     "start_time": "2023-07-02T16:55:49.348940Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "sampler = torch_data.DistributedSampler(solver.train_set, solver.world_size, solver.rank)\n",
    "dataloader = data.DataLoader(solver.train_set, 32, sampler=sampler, num_workers=solver.num_worker)\n",
    "\n",
    "_train_data = list(dataloader)[0]\n",
    "_train_data = utils.cuda(_train_data, device=solver.device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T18:28:55.380049Z",
     "start_time": "2023-07-02T18:28:55.316263Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "graph = _train_data[\"graph\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T18:28:57.752993Z",
     "start_time": "2023-07-02T18:28:57.752550Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([8480, 21])"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.node_feature.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T18:28:58.467677Z",
     "start_time": "2023-07-02T18:28:58.438185Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'graph': PackedProtein(batch_size=32, num_atoms=[0, 0, 0, ..., 0, 0, 0], num_bonds=[0, 0, 0, ..., 0, 0, 0], num_residues=[265, 265, 265, ..., 265, 265, 265]), 'target': tensor([1.6360, 0.8175, 0.8215, 0.7537, 2.2665, 1.1582, 1.5202, 4.0336, 1.1568,\n",
      "        5.3907, 1.0487, 1.5217, 0.8196, 1.4421, 1.5760, 1.5873, 0.0132, 1.0237,\n",
      "        2.7889, 1.3077, 0.0940, 0.8833, 1.7847, 1.4719, 0.8586, 0.9630, 0.5241,\n",
      "        0.5729, 1.7041, 1.4475, 0.8713, 0.6580])}\n",
      "{'graph': PackedProtein(batch_size=32, num_atoms=[0, 0, 0, ..., 0, 0, 0], num_bonds=[0, 0, 0, ..., 0, 0, 0], num_residues=[265, 265, 265, ..., 265, 265, 265]), 'target': tensor([0.9274, 0.8640, 1.2464, 0.6086, 1.4160, 1.1426, 0.5655, 0.8681, 0.5743,\n",
      "        1.9338, 0.5045, 4.0731, 0.8410, 1.6874, 1.0474, 0.8725, 0.5061, 1.3368,\n",
      "        1.2616, 0.5374, 2.6509, 0.6427, 5.0028, 1.3816, 0.9215, 1.1198, 2.4859,\n",
      "        0.0201, 1.8382, 1.2840, 0.5493, 0.5214])}\n",
      "{'graph': PackedProtein(batch_size=32, num_atoms=[0, 0, 0, ..., 0, 0, 0], num_bonds=[0, 0, 0, ..., 0, 0, 0], num_residues=[265, 265, 265, ..., 265, 265, 265]), 'target': tensor([0.7000, 1.7159, 2.3735, 1.9363, 0.0171, 1.3046, 1.4893, 0.5825, 1.7614,\n",
      "        1.0453, 0.7373, 1.0879, 2.3508, 1.4901, 0.6312, 1.1185, 2.4012, 1.4611,\n",
      "        1.1151, 0.6867, 1.9262, 3.2571, 0.5947, 1.6780, 0.5958, 0.7237, 3.9107,\n",
      "        0.7062, 0.8360, 0.6749, 0.5472, 1.2827])}\n",
      "{'graph': PackedProtein(batch_size=32, num_atoms=[0, 0, 0, ..., 0, 0, 0], num_bonds=[0, 0, 0, ..., 0, 0, 0], num_residues=[265, 265, 265, ..., 265, 265, 265]), 'target': tensor([1.6258e+00, 7.0606e-02, 6.2310e-01, 8.7460e-01, 7.5426e-01, 5.0199e-01,\n",
      "        0.0000e+00, 5.0420e-01, 8.7681e-01, 9.6194e-01, 1.0020e+00, 6.9434e-01,\n",
      "        5.9892e-01, 9.7179e-01, 2.4872e+00, 3.8915e+00, 1.3481e+00, 3.3238e+00,\n",
      "        9.4058e-01, 9.4183e-01, 1.2154e+00, 1.3135e+00, 1.6902e+00, 1.0651e+00,\n",
      "        2.4243e+00, 7.5625e-01, 4.7529e-03, 8.2079e-01, 9.0731e-01, 1.0905e-03,\n",
      "        5.9427e-01, 5.2235e-01])}\n",
      "{'graph': PackedProtein(batch_size=32, num_atoms=[0, 0, 0, ..., 0, 0, 0], num_bonds=[0, 0, 0, ..., 0, 0, 0], num_residues=[265, 265, 265, ..., 265, 265, 265]), 'target': tensor([0.7213, 1.1724, 0.0395, 0.8191, 0.5300, 3.1453, 0.5857, 2.3963, 3.7035,\n",
      "        4.1128, 0.9747, 0.6491, 4.2392, 2.3679, 1.9477, 0.6366, 1.0466, 0.6189,\n",
      "        1.0972, 0.6852, 1.4219, 0.8788, 0.6578, 0.6841, 1.0438, 3.7203, 3.3570,\n",
      "        1.1631, 0.0000, 0.6909, 1.0741, 1.5116])}\n",
      "{'graph': PackedProtein(batch_size=32, num_atoms=[0, 0, 0, ..., 0, 0, 0], num_bonds=[0, 0, 0, ..., 0, 0, 0], num_residues=[265, 265, 265, ..., 265, 265, 265]), 'target': tensor([2.0873, 1.4459, 1.7917, 0.5721, 3.6086, 0.5845, 1.1139, 0.5528, 0.8771,\n",
      "        0.6210, 0.9363, 1.3472, 1.3115, 1.8587, 0.2342, 0.6546, 0.9443, 0.5945,\n",
      "        0.9400, 0.5076, 1.1705, 0.6330, 0.8462, 0.8758, 0.8067, 0.5654, 2.2694,\n",
      "        1.9186, 0.9461, 1.7121, 0.6638, 3.1583])}\n",
      "{'graph': PackedProtein(batch_size=32, num_atoms=[0, 0, 0, ..., 0, 0, 0], num_bonds=[0, 0, 0, ..., 0, 0, 0], num_residues=[265, 265, 265, ..., 265, 265, 265]), 'target': tensor([1.6502e-02, 2.9258e+00, 7.3648e-01, 7.6515e-01, 1.3186e+00, 2.1890e+00,\n",
      "        5.5758e-01, 7.5810e-02, 7.8198e-01, 1.1666e+00, 7.9911e-01, 5.0753e+00,\n",
      "        1.1379e+00, 1.3840e+00, 7.9629e-01, 2.1853e-02, 1.1987e+00, 1.7614e+00,\n",
      "        1.4995e+00, 2.0880e+00, 5.1714e-03, 8.4013e-01, 9.2690e-01, 2.0586e+00,\n",
      "        4.7745e+00, 4.4798e-03, 5.8370e-01, 6.7637e-01, 1.6412e+00, 2.4060e+00,\n",
      "        9.8239e-01, 1.0694e+00])}\n",
      "{'graph': PackedProtein(batch_size=32, num_atoms=[0, 0, 0, ..., 0, 0, 0], num_bonds=[0, 0, 0, ..., 0, 0, 0], num_residues=[265, 265, 265, ..., 265, 265, 265]), 'target': tensor([0.7463, 0.7014, 0.7599, 3.1809, 2.6981, 1.4343, 0.7927, 1.3680, 0.6811,\n",
      "        0.6004, 0.9513, 0.2329, 0.5324, 1.2492, 2.3575, 2.8883, 2.6643, 1.1834,\n",
      "        0.7179, 1.2924, 1.5026, 2.5528, 1.3273, 0.6083, 1.0885, 0.8609, 1.5670,\n",
      "        0.0054, 0.0050, 1.2815, 0.9059, 1.4139])}\n",
      "{'graph': PackedProtein(batch_size=32, num_atoms=[0, 0, 0, ..., 0, 0, 0], num_bonds=[0, 0, 0, ..., 0, 0, 0], num_residues=[265, 265, 265, ..., 265, 265, 265]), 'target': tensor([1.0977, 1.0000, 0.5050, 2.4816, 0.0056, 3.0864, 2.0737, 1.5705, 2.6957,\n",
      "        1.5482, 0.6977, 1.7515, 0.5472, 0.9062, 1.3729, 0.6172, 0.9283, 1.8807,\n",
      "        1.0447, 0.5465, 4.0460, 2.1521, 1.1379, 0.5654, 0.6536, 0.0041, 2.4422,\n",
      "        1.2660, 2.0373, 2.1636, 1.0213, 2.4545])}\n",
      "{'graph': PackedProtein(batch_size=32, num_atoms=[0, 0, 0, ..., 0, 0, 0], num_bonds=[0, 0, 0, ..., 0, 0, 0], num_residues=[265, 265, 265, ..., 265, 265, 265]), 'target': tensor([8.8098e-01, 6.1519e-01, 6.9564e-03, 2.2863e+00, 4.0401e-01, 1.4466e+00,\n",
      "        5.2354e-01, 7.0984e-01, 4.3877e+00, 7.3882e-01, 2.7994e+00, 5.6925e-01,\n",
      "        1.1410e+00, 3.6006e+00, 3.6871e+00, 9.0258e-01, 2.7702e+00, 3.6861e+00,\n",
      "        1.2494e+00, 5.8565e-01, 1.6210e+00, 7.0260e-01, 5.9336e-01, 2.6558e-03,\n",
      "        1.1054e+00, 1.0935e+00, 1.7782e+00, 3.2984e+00, 1.3593e+00, 8.8080e-01,\n",
      "        1.7329e+00, 8.6030e-01])}\n",
      "{'graph': PackedProtein(batch_size=32, num_atoms=[0, 0, 0, ..., 0, 0, 0], num_bonds=[0, 0, 0, ..., 0, 0, 0], num_residues=[265, 265, 265, ..., 265, 265, 265]), 'target': tensor([0.5179, 0.0175, 2.5112, 0.7107, 3.0812, 0.8968, 1.1655, 0.7139, 1.7450,\n",
      "        3.9015, 2.8003, 1.9719, 0.8347, 3.6592, 1.9186, 0.9266, 1.3525, 1.6455,\n",
      "        0.5601, 1.4525, 0.7176, 0.9278, 0.7314, 0.5356, 1.1128, 0.5177, 3.1674,\n",
      "        0.6284, 2.4031, 1.3316, 0.5395, 0.5341])}\n",
      "{'graph': PackedProtein(batch_size=29, num_atoms=[0, 0, 0, ..., 0, 0, 0], num_bonds=[0, 0, 0, ..., 0, 0, 0], num_residues=[265, 265, 265, ..., 265, 265, 265]), 'target': tensor([0.5349, 0.5482, 4.0291, 0.6991, 2.0870, 0.0881, 0.9721, 0.0804, 1.9100,\n",
      "        2.8676, 1.1502, 0.0144, 0.5079, 3.0545, 0.0057, 2.8038, 1.2771, 0.8095,\n",
      "        1.2162, 0.6894, 1.0915, 0.7797, 2.4603, 2.8339, 1.6436, 1.3842, 1.2884,\n",
      "        0.9571, 0.8360])}\n"
     ]
    }
   ],
   "source": [
    "for item in dataloader:\n",
    "    print(item)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T18:29:45.163368Z",
     "start_time": "2023-07-02T18:29:45.096906Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T18:30:57.891460Z",
     "start_time": "2023-07-02T18:30:57.884950Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "graph = _train_data[\"graph\"]\n",
    "model = solver.model\n",
    "\n",
    "all_loss = torch.tensor(0, dtype=torch.float32, device=model.device)\n",
    "metric = {}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-30T09:07:45.288196Z",
     "start_time": "2023-06-30T09:07:45.285907Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "output_1 = model.model(graph, graph.node_feature.float(), all_loss=all_loss, metric=metric)['graph_feature']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-30T09:07:54.671914Z",
     "start_time": "2023-06-30T09:07:45.286050Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import torch\n",
    "output_2 = torch.load(\"/home/zhiqiang/PEER_Benchmark/script/extracted_embeddings/GB1_ESM-1b-fix.pt\")\n",
    "output_2 = utils.cuda(output_2, device=solver.device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-30T09:07:54.717343Z",
     "start_time": "2023-06-30T09:07:54.712188Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "pred_1 = model.mlp(output_1)\n",
    "pred_2 = model.mlp(output_2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-30T09:07:54.717564Z",
     "start_time": "2023-06-30T09:07:54.712308Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([-0.0675, -0.0669, -0.0691, -0.0678, -0.0667, -0.0681, -0.0690, -0.0667,\n        -0.0679, -0.0674, -0.0687, -0.0670, -0.0686, -0.0684, -0.0679, -0.0675,\n        -0.0668, -0.0682, -0.0684, -0.0664, -0.0690, -0.0672, -0.0676, -0.0667,\n        -0.0666, -0.0686, -0.0681, -0.0687, -0.0676, -0.0679], device='cuda:0',\n       grad_fn=<SliceBackward0>)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_1.squeeze()[:30]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-30T09:10:54.428542Z",
     "start_time": "2023-06-30T09:10:54.383763Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([-0.0675, -0.0669, -0.0691, -0.0678, -0.0667, -0.0681, -0.0690, -0.0667,\n        -0.0679, -0.0674, -0.0687, -0.0670, -0.0686, -0.0684, -0.0679, -0.0675,\n        -0.0668, -0.0682, -0.0684, -0.0664, -0.0690, -0.0672, -0.0676, -0.0667,\n        -0.0666, -0.0686, -0.0681, -0.0687, -0.0676, -0.0679], device='cuda:0',\n       grad_fn=<SliceBackward0>)"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_2.squeeze()[:30]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-30T09:10:57.518405Z",
     "start_time": "2023-06-30T09:10:57.492902Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.0251, -0.0058,  0.0169,  ..., -0.0214, -0.0263, -0.0201],\n        [ 0.0249,  0.0020, -0.0046,  ..., -0.0105, -0.0145, -0.0168],\n        [-0.0074,  0.0063,  0.0077,  ..., -0.0274, -0.0223,  0.0219],\n        ...,\n        [ 0.0054,  0.0239, -0.0181,  ...,  0.0043, -0.0188, -0.0111],\n        [-0.0050,  0.0067, -0.0128,  ..., -0.0103, -0.0037, -0.0103],\n        [ 0.0199,  0.0276,  0.0153,  ..., -0.0046,  0.0172,  0.0022]],\n       device='cuda:0')"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.mlp.layers[0].state_dict()[\"weight\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-30T09:35:29.202940Z",
     "start_time": "2023-06-30T09:35:29.159076Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.0164, 0.0162, 0.0162,  ..., 0.0164, 0.0161, 0.0158], device='cuda:0')"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.mlp.layers[0].state_dict()[\"weight\"].std(0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-30T09:22:55.451430Z",
     "start_time": "2023-06-30T09:22:55.434089Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "torch.save(model.mlp.state_dict(), \"/home/zhiqiang/PEER_Benchmark/script/extracted_params/raw_mlp.pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-30T09:39:18.009391Z",
     "start_time": "2023-06-30T09:39:17.979286Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# solver, best_epoch = train_and_validate(cfg, solver)\n",
    "\"\"\"start solver, best_epoch = train_and_validate(cfg, solver)\"\"\"\n",
    "step = math.ceil(cfg.train.num_epoch / 10)\n",
    "best_score = float(\"-inf\")\n",
    "best_epoch = -1\n",
    "\n",
    "# if not cfg.train.num_epoch > 0:\n",
    "#     return solver, best_epoch\n",
    "\n",
    "for i in range(0, cfg.train.num_epoch, step):\n",
    "    kwargs = cfg.train.copy()\n",
    "    kwargs[\"num_epoch\"] = min(step, cfg.train.num_epoch - i)\n",
    "    solver.model.split = \"train\"\n",
    "    # solver.train(**kwargs)\n",
    "    \"\"\"start solver.train(**kwargs)\"\"\"\n",
    "    from torch import nn\n",
    "    from itertools import islice\n",
    "    batch_per_epoch = None\n",
    "    num_epoch = kwargs[\"num_epoch\"]\n",
    "    sampler = torch_data.DistributedSampler(solver.train_set, solver.world_size, solver.rank)\n",
    "    dataloader = data.DataLoader(solver.train_set, solver.batch_size, sampler=sampler, num_workers=solver.num_worker)\n",
    "    batch_per_epoch = batch_per_epoch or len(dataloader)\n",
    "    model = solver.model\n",
    "    model.split = \"train\"\n",
    "    model.train()\n",
    "\n",
    "    for epoch in solver.meter(num_epoch):\n",
    "        sampler.set_epoch(epoch)\n",
    "\n",
    "        metrics = []\n",
    "        start_id = 0\n",
    "        # the last gradient update may contain less than gradient_interval batches\n",
    "        gradient_interval = min(batch_per_epoch - start_id, solver.gradient_interval)\n",
    "\n",
    "        all_loss = 0\n",
    "        for batch_id, batch in enumerate(islice(dataloader, batch_per_epoch)):\n",
    "            if solver.device.type == \"cuda\":\n",
    "                batch = utils.cuda(batch, device=solver.device)\n",
    "\n",
    "            # loss_1, metric = model(batch)\n",
    "            from torch.nn import functional as F\n",
    "            from torchdrug.layers import functional\n",
    "\n",
    "            all_loss = torch.tensor(0, dtype=torch.float32, device=model.device)\n",
    "            metric = {}\n",
    "\n",
    "            # pred = model.predict(batch, all_loss, metric)\n",
    "            graph = batch[\"graph\"]\n",
    "            if model.graph_construction_model:\n",
    "                graph = model.graph_construction_model(graph)\n",
    "            output = model.model(graph, graph.node_feature.float(), all_loss=all_loss, metric=metric)\n",
    "            pred = model.mlp(output[\"graph_feature\"])\n",
    "            if model.normalization:\n",
    "                pred = pred * model.std + model.mean\n",
    "\n",
    "            # if all([t not in batch for t in self.task]):\n",
    "            #     # unlabeled data\n",
    "            #     return all_loss, metric\n",
    "\n",
    "            target = model.target(batch)\n",
    "            labeled = ~torch.isnan(target)\n",
    "            target[~labeled] = 0\n",
    "\n",
    "            for criterion, weight in model.criterion.items():\n",
    "                loss = F.mse_loss(pred, target, reduction=\"mean\")\n",
    "\n",
    "                name = tasks._get_criterion_name(criterion)\n",
    "                metric[name] = loss\n",
    "            loss_1, metric = loss, metric\n",
    "\n",
    "            # if not loss.requires_grad:\n",
    "            #     raise RuntimeError(\"Loss doesn't require grad. Did you define any loss in the task?\")\n",
    "            loss = loss_1 / gradient_interval\n",
    "            loss.backward()\n",
    "            metrics.append(metric)\n",
    "            all_loss += loss\n",
    "            # print(batch_id, \"Two loss: \", round(loss.item(), 3), round(all_loss.item(), 3))\n",
    "\n",
    "            solver.optimizer.step()\n",
    "            # print(\"optimiser\")\n",
    "            # if batch_id - start_id + 1 == gradient_interval:\n",
    "            #     solver.optimizer.step()\n",
    "            #     solver.optimizer.zero_grad()\n",
    "            #\n",
    "            #     metric = utils.stack(metrics, dim=0)\n",
    "            #     metric = utils.mean(metric, dim=0)\n",
    "            #     if solver.world_size > 1:\n",
    "            #         metric = comm.reduce(metric, op=\"mean\")\n",
    "            #     solver.meter.update(metric)\n",
    "            #\n",
    "            #     metrics = []\n",
    "            #     start_id = batch_id + 1\n",
    "            #     gradient_interval = min(batch_per_epoch - start_id, solver.gradient_interval)\n",
    "        print(\"Loss: \", all_loss)\n",
    "\n",
    "        # if solver.scheduler:\n",
    "        #     # False\n",
    "        #     solver.scheduler.step()\n",
    "    \"\"\"end solver.train(**kwargs)\"\"\"\n",
    "\n",
    "\n",
    "    solver.model.split = \"valid\"\n",
    "    # metric = solver.evaluate(\"valid\")\n",
    "    \"\"\"start metric = solver.evaluate(\"valid\")\"\"\"\n",
    "    split, log = \"valid\", True\n",
    "    if comm.get_rank() == 0:\n",
    "        logger.warning(pretty.separator)\n",
    "        logger.warning(\"Evaluate on %s\" % split)\n",
    "    test_set = getattr(solver, \"%s_set\" % split)\n",
    "    sampler = torch_data.DistributedSampler(test_set, solver.world_size, solver.rank)\n",
    "    dataloader = data.DataLoader(test_set, solver.batch_size, sampler=sampler, num_workers=solver.num_worker)\n",
    "    model = solver.model\n",
    "    model.split = split\n",
    "\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    targets = []\n",
    "    for batch in dataloader:\n",
    "        if solver.device.type == \"cuda\":\n",
    "            batch = utils.cuda(batch, device=solver.device)\n",
    "\n",
    "        pred, target = model.predict_and_target(batch)\n",
    "        preds.append(pred)\n",
    "        targets.append(target)\n",
    "\n",
    "    pred = utils.cat(preds)\n",
    "    target = utils.cat(targets)\n",
    "    if solver.world_size > 1:\n",
    "        pred = comm.cat(pred)\n",
    "        target = comm.cat(target)\n",
    "    metric = model.evaluate(pred, target)\n",
    "    if log:\n",
    "        solver.meter.log(metric, category=\"%s/epoch\" % solver)\n",
    "    solver.batch_size = cfg.engine.batch_size\n",
    "    \"\"\"end metric = solver.evaluate(\"valid\")\"\"\"\n",
    "\n",
    "    score = []\n",
    "    for k, v in metric.items():\n",
    "        if k.startswith(cfg.eval_metric):\n",
    "            if \"root mean squared error\" in cfg.eval_metric:\n",
    "                score.append(-v)\n",
    "            else:\n",
    "                score.append(v)\n",
    "    score = sum(score) / len(score)\n",
    "    if score > best_score:\n",
    "        # print(\"Update best epoch.\")\n",
    "        if best_epoch > -1:\n",
    "            # remove old best epoch model parameters before saving new parameters\n",
    "            to_remove_path = os.path.expanduser(\"model_epoch_%d.pth\" % best_epoch)\n",
    "            # print('removing old parameters at %s' % to_remove_path)\n",
    "            os.remove(to_remove_path)\n",
    "\n",
    "        best_score = score\n",
    "        best_epoch = solver.epoch\n",
    "\n",
    "        # only save epoch model parameters when it is another best epoch\n",
    "        solver.save(\"model_epoch_%d.pth\" % solver.epoch)\n",
    "# clean GPU memory\n",
    "clean_gpu_memory()\n",
    "solver.load(\"model_epoch_%d.pth\" % best_epoch)\n",
    "\n",
    "if comm.get_rank() == 0:\n",
    "    logger.warning(\"Best epoch on valid: %d\" % best_epoch)\n",
    "\"\"\"end solver, best_epoch = train_and_validate(cfg, solver)\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # test(cfg, solver)\n",
    "# \"\"\"start test(cfg, solver)\"\"\"\n",
    "# if \"test_batch_size\" in cfg:\n",
    "#     solver.batch_size = cfg.test_batch_size\n",
    "# solver.model.split = \"valid\"\n",
    "# solver.evaluate(\"valid\")\n",
    "# solver.model.split = \"test\"\n",
    "# solver.evaluate(\"test\")\n",
    "# \"\"\"end test(cfg, solver)\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
